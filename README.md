# ğŸ” DÃ©tection de Fraudes par ChÃ¨que

**Projet de Fouille de DonnÃ©es Massives - Master 2 SISE**  
*UniversitÃ© LumiÃ¨re Lyon 2 - FÃ©vrier 2026*

---

## ğŸ‘¥ Auteurs

- **Yassine CHENIOUR**
- **Modou MBOUP**

---

## ğŸ“‹ Description

Ce projet porte sur la **dÃ©tection de fraudes bancaires par chÃ¨que** dans un contexte de donnÃ©es fortement dÃ©sÃ©quilibrÃ©es. Nous analysons 4,6 millions de transactions rÃ©elles provenant de la grande distribution franÃ§aise (fÃ©vrier-novembre 2017), avec un taux de fraude de seulement 0,60% (ratio 1:165).

### ğŸ¯ Objectifs

1. **Partie 1** : Maximiser la F-mesure en comparant plusieurs approches de classification
2. **Partie 2** : Optimiser le profit en intÃ©grant une matrice de coÃ»ts mÃ©tier rÃ©aliste

### ğŸ† RÃ©sultats principaux

- **Meilleure F-mesure** : 0.148 (XGBoost avec seuil ajustÃ©) â†’ +85% vs littÃ©rature
- **Meilleure marge** : 2 055 747â‚¬ sur 3 mois (XGBoost avec seuil ajustÃ© pour profit)
- **Insight clÃ©** : Optimiser la F-mesure â‰  Maximiser le profit (+2,3% de gain)

---

## ğŸ“ Structure du projet

```
SISE_FraudsDetection/
â”œâ”€â”€ README.md                              # Ce fichier
â”œâ”€â”€ Rapport_FDM_MBOUP_CHENIOUR.pdf        # Rapport complet (34 pages)
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Data_Projet1.txt                  # Dataset brut (4,6M transactions)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ preprocessing.ipynb                # PrÃ©traitement et analyse exploratoire
â”‚   â”œâ”€â”€ modelisation.ipynb                 # Partie 1 : Optimisation F-mesure
â”‚   â””â”€â”€ maximisation_de_la_marge.ipynb    # Partie 2 : Optimisation profit
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ resultats_modelisation_partie1.csv
â”‚   â”œâ”€â”€ resultats_maximisation_de_la_marge.csv
â”‚   â”œâ”€â”€ resume_modelisation.txt
â”‚   â””â”€â”€ resultats_maximisation_de_la_marge.txt
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ sujet.pdf                          # Ã‰noncÃ© du projet
    â”œâ”€â”€ rapport_FDM.zip                    # Sources LaTeX du rapport
    â””â”€â”€ rapport_FDM/
        â”œâ”€â”€ main.tex
        â”œâ”€â”€ references.bib
        â”œâ”€â”€ sections/                      # Fichiers LaTeX par section
        â”‚   â”œâ”€â”€ 0_resume.tex
        â”‚   â”œâ”€â”€ 1_introduction.tex
        â”‚   â”œâ”€â”€ 2_analyse_donnees.tex
        â”‚   â”œâ”€â”€ 3_methodologie.tex
        â”‚   â”œâ”€â”€ 4_experiences.tex
        â”‚   â””â”€â”€ 5_conclusion.tex
        â””â”€â”€ figures/                       # Visualisations du rapport
            â”œâ”€â”€ confusion_matrix_xgboost.png
            â”œâ”€â”€ correlation_matrix.png
            â”œâ”€â”€ distributions_VC.png
            â”œâ”€â”€ distribution_classes.png
            â”œâ”€â”€ distribution_montants.png
            â”œâ”€â”€ evolution_temporelle_fraudes.png
            â”œâ”€â”€ resultats_partie1_complet.png
            â””â”€â”€ resultats_partie2_complet.png
```

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.11+
- Jupyter Notebook

### DÃ©pendances

```bash
pip install pandas numpy scikit-learn xgboost imbalanced-learn matplotlib seaborn
```

---

## ğŸ“Š Dataset

- **Source** : Grande distribution franÃ§aise (collaboration FNCI/Banque de France)
- **PÃ©riode** : FÃ©vrier-novembre 2017
- **Taille** : 4 645 652 transactions
- **Variables** : 23 variables (20 features aprÃ¨s prÃ©traitement)
- **DÃ©sÃ©quilibre** : 0,64% fraudes (29 831 sur 4,6M)
- **Split temporel** : 
  - Train : FÃ©vrier-AoÃ»t 2017 (7 mois)
  - Test : Septembre-Novembre 2017 (3 mois)

---

## ğŸ› ï¸ MÃ©thodologie

### Approches testÃ©es (9 modÃ¨les)

**Techniques de rÃ©Ã©chantillonnage :**
- SMOTE + Logistic Regression
- UnderSampling + Logistic Regression
- XGBoost + SMOTE

**Approches cost-sensitive :**
- Logistic Regression + class_weight
- Random Forest + class_weight
- Balanced Random Forest
- XGBoost + scale_pos_weight

**Optimisation du seuil :**
- XGBoost avec ajustement du seuil de dÃ©cision

### Algorithmes utilisÃ©s

- RÃ©gression Logistique (baseline)
- Random Forest
- XGBoost (meilleur modÃ¨le)

---

## ğŸ“ˆ RÃ©sultats

### Partie 1 : Optimisation F-mesure

| ModÃ¨le | F-mesure | PrÃ©cision | Rappel |
|--------|----------|-----------|--------|
| **XGBoost (seuil=0.939)** | **0.148** | 0.184 | 0.124 |
| XGBoost + SMOTE | 0.130 | 0.157 | 0.112 |
| SMOTE + LogReg | 0.094 | 0.156 | 0.067 |

### Partie 2 : Optimisation Profit

| ModÃ¨le | Marge (â‚¬) | F1 | PrÃ©cision | Rappel |
|--------|-----------|----|-----------|---------| 
| **XGBoost (seuil=0.85)** | **2 055 747** | 0.104 | 0.065 | 0.257 |
| UnderSampling + LogReg | 2 040 856 | 0.067 | 0.037 | 0.356 |
| XGBoost + SMOTE | 2 018 959 | 0.136 | 0.127 | 0.147 |

### Comparaison F-mesure vs Profit

- **Gain de marge** : +45 891â‚¬ (+2,3%) en optimisant directement le profit
- **Conclusion** : La F-mesure n'est pas un proxy fiable du profit rÃ©el

---

## ğŸ”§ Utilisation

### 1. PrÃ©traitement des donnÃ©es

```bash
jupyter notebook notebooks/preprocessing.ipynb
```

Contenu :
- Conversion des formats numÃ©riques (notation europÃ©enne)
- Analyse exploratoire (distributions, corrÃ©lations)
- Split temporel train/test
- Exclusion des variables redondantes (VerifianceCPT2/3)

### 2. Partie 1 - Optimisation F-mesure

```bash
jupyter notebook notebooks/modelisation.ipynb
```

Compare 9 approches et identifie le modÃ¨le maximisant la F-mesure.

### 3. Partie 2 - Optimisation Profit

```bash
jupyter notebook notebooks/maximisation_de_la_marge.ipynb
```

IntÃ¨gre la matrice de coÃ»ts mÃ©tier et optimise la marge commerciale.

### 4. Consulter les rÃ©sultats

Les rÃ©sultats dÃ©taillÃ©s sont disponibles dans le dossier `results/` :
- `resultats_modelisation_partie1.csv` : MÃ©triques Partie 1
- `resultats_maximisation_de_la_marge.csv` : MÃ©triques Partie 2
- Fichiers `.txt` : RÃ©sumÃ©s textuels

---

## ğŸ“„ Documentation complÃ¨te

Le **rapport complet (34 pages)** est disponible Ã  la racine : `Rapport_FDM_MBOUP_CHENIOUR.pdf`

Contenu du rapport :
- RÃ©sumÃ© exÃ©cutif
- Introduction et Ã©tat de l'art
- Analyse exploratoire approfondie
- MÃ©thodologie dÃ©taillÃ©e (algorithmes, rÃ©Ã©chantillonnage, mÃ©triques)
- RÃ©sultats comparatifs des 9 modÃ¨les
- Analyses statistiques et visualisations
- Limites identifiÃ©es et perspectives d'amÃ©lioration

**Sources LaTeX** : Disponibles dans `docs/rapport_FDM/` pour reproductibilitÃ© complÃ¨te.

---

## ğŸ”‘ Points clÃ©s

âœ… **9 modÃ¨les** testÃ©s systÃ©matiquement  
âœ… **F-mesure** : 0.148 (+85% vs littÃ©rature)  
âœ… **Profit** : 2,06Mâ‚¬ sur 3 mois (~8,2Mâ‚¬/an)  
âœ… **DÃ©monstration** empirique : F-mesure â‰  Profit  
âœ… **Dataset rÃ©el** de 4,6M transactions  

---

## ğŸ“š RÃ©fÃ©rences

- Breiman, L. (2001). Random Forests. *Machine Learning*, 45(1), 5-32.
- Chawla, N. V. et al. (2002). SMOTE: Synthetic Minority Over-sampling Technique. *JAIR*, 16, 321-357.
- Chen, T. & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. *KDD'16*.
- Metzler, G. (2019). Learning from Imbalanced Data. ThÃ¨se, UniversitÃ© de Lyon.

---

## ğŸ“§ Contact

Pour toute question concernant ce projet :
- Yassine CHENIOUR
- Modou MBOUP

**Formation** : Master 2 Informatique - SISE  
**UniversitÃ©** : LumiÃ¨re Lyon 2  
**Date** : FÃ©vrier 2026

---

## ğŸ“ Licence

Ce projet est rÃ©alisÃ© dans un cadre acadÃ©mique (Master 2 SISE - UniversitÃ© Lyon 2).

---

â­ **Note** : Ce projet a Ã©tÃ© rÃ©alisÃ© avec des donnÃ©es rÃ©elles en collaboration avec la FNCI et la Banque de France.
